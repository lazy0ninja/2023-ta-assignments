---
title: "Exercise 2 starter"
output: pdf_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(lubridate)
library(arrow)
```

## Load data

Load the following data: + applications from `app_data_sample.parquet` + edges from `edges_sample.csv`

```{r load-data}
# change to your own path!
data_path <- "/Users/kaz/Desktop/MMA - WINTER Code/"
applications <- read_feather(paste0(data_path,"app_data_starter.feather"))

applications
```

## Get gender for examiners

We'll get gender based on the first name of the examiner, which is recorded in the field `examiner_name_first`. We'll use library `gender` for that, relying on a modified version of their own [example](https://cran.r-project.org/web/packages/gender/vignettes/predicting-gender.html).

Note that there are over 2 million records in the applications table -- that's because there are many records for each examiner, as many as the number of applications that examiner worked on during this time frame. Our first step therefore is to get all *unique* names in a separate list `examiner_names`. We will then guess gender for each one and will join this table back to the original dataset. So, let's get names without repetition:

```{r gender-1}
library(gender)
#install_genderdata_package() # only run this line the first time you use the package, to get data for it

# get a list of first names without repetitions
examiner_names <- applications %>% 
  distinct(examiner_name_first)

examiner_names
```

Now let's use function `gender()` as shown in the example for the package to attach a gender and probability to each name and put the results into the table `examiner_names_gender`

```{r gender-2}
# get a table of names and gender

examiner_names_gender <- examiner_names %>% 
  do(results = gender(.$examiner_name_first, method = "ssa")) %>% 
  unnest(cols = c(results), keep_empty = TRUE) %>% 
  select(
    examiner_name_first = name,
    gender,
    proportion_female
  )

examiner_names_gender
```


Finally, let's join that table back to our original applications data and discard the temporary tables we have just created to reduce clutter in our environment.

```{r gender-3}
# remove extra colums from the gender table
examiner_names_gender <- examiner_names_gender %>% 
  select(examiner_name_first, gender)

# joining gender back to the dataset
applications <- applications %>% 
  left_join(examiner_names_gender, by = "examiner_name_first")

# cleaning up
rm(examiner_names)
rm(examiner_names_gender)
gc()

```

```{r}
# colsum na
colSums(is.na(applications))
```



## Guess the examiner's race

We'll now use package `wru` to estimate likely race of an examiner. Just like with gender, we'll get a list of unique names first, only now we are using surnames.

```{r race-1}
library(wru)

examiner_surnames <- applications %>% 
  select(surname = examiner_name_last) %>% 
  distinct()

examiner_surnames
```

We'll follow the instructions for the package outlined here <https://github.com/kosukeimai/wru>.

```{r race-2}
examiner_race <- predict_race(voter.file = examiner_surnames, surname.only = T) %>% 
  as_tibble()

examiner_race
```

As you can see, we get probabilities across five broad US Census categories: white, black, Hispanic, Asian and other. (Some of you may correctly point out that Hispanic is not a race category in the US Census, but these are the limitations of this package.)

Our final step here is to pick the race category that has the highest probability for each last name and then join the table back to the main applications table. See this example for comparing values across columns: <https://www.tidyverse.org/blog/2020/04/dplyr-1-0-0-rowwise/>. And this one for `case_when()` function: <https://dplyr.tidyverse.org/reference/case_when.html>.

```{r race-3}
examiner_race <- examiner_race %>% 
  mutate(max_race_p = pmax(pred.asi, pred.bla, pred.his, pred.oth, pred.whi)) %>% 
  mutate(race = case_when(
    max_race_p == pred.asi ~ "Asian",
    max_race_p == pred.bla ~ "black",
    max_race_p == pred.his ~ "Hispanic",
    max_race_p == pred.oth ~ "other",
    max_race_p == pred.whi ~ "white",
    TRUE ~ NA_character_
  ))

examiner_race
```

Let's join the data back to the applications table.

```{r race-4}
# removing extra columns
examiner_race <- examiner_race %>% 
  select(surname,race)

applications <- applications %>% 
  left_join(examiner_race, by = c("examiner_name_last" = "surname"))

rm(examiner_race)
rm(examiner_surnames)
gc()
```

## Examiner's tenure

To figure out the timespan for which we observe each examiner in the applications data, let's find the first and the last observed date for each examiner. We'll first get examiner IDs and application dates in a separate table, for ease of manipulation. We'll keep examiner ID (the field `examiner_id`), and earliest and latest dates for each application (`filing_date` and `appl_status_date` respectively). We'll use functions in package `lubridate` to work with date and time values.

```{r tenure-1}
library(lubridate) # to work with dates

examiner_dates <- applications %>% 
  select(examiner_id, filing_date, appl_status_date) 

examiner_dates
```

The dates look inconsistent in terms of formatting. Let's make them consistent. We'll create new variables `start_date` and `end_date`.

```{r tenure-2}
examiner_dates <- examiner_dates %>% 
  mutate(start_date = ymd(filing_date), end_date = as_date(dmy_hms(appl_status_date)))
```

Let's now identify the earliest and the latest date for each examiner and calculate the difference in days, which is their tenure in the organization.

```{r tenure-3}
examiner_dates <- examiner_dates %>% 
  group_by(examiner_id) %>% 
  summarise(
    earliest_date = min(start_date, na.rm = TRUE), 
    latest_date = max(end_date, na.rm = TRUE),
    tenure_days = interval(earliest_date, latest_date) %/% days(1)
    ) %>% 
  filter(year(latest_date)<2018)

examiner_dates
```

Joining back to the applications data.

```{r tenure-4}
applications <- applications %>% 
  left_join(examiner_dates, by = "examiner_id")

rm(examiner_dates)
gc()
```

Save file as processed variables, to skip these steps in the following exercises.

```{r}
write_feather(applications, paste0(data_path,"app_data_starter_coded.feather"))
```

# Rest of the exercise
```{r}
# load data
data_path <- "/Users/kaz/Desktop/MMA - WINTER Code/"
applications <- read_feather(paste0(data_path,"app_data_starter_coded.feather"))
```

# Create Variables
```{r}
library(tidyverse)
library(lubridate)

# Convert filing_date to Date format and create a quarter variable
applications$filing_date <- as.Date(applications$filing_date)
applications$quarter <- paste0(year(applications$filing_date), "/", quarter(applications$filing_date))

# Aggregate applications by quarter and examiner
applications <- applications %>%
  group_by(quarter, examiner_id) %>%
  mutate(new_applications = n_distinct(application_number)) %>%
  ungroup()

applications <- applications %>%
  group_by(quarter, examiner_id) %>%
  mutate(ISSUED_applications = sum(disposal_type == "ISS" & !duplicated(application_number)))

applications <- applications %>%
  group_by(quarter, examiner_id) %>%
  mutate(abn_applications = sum(disposal_type == "ABN" & !duplicated(application_number)))

applications <- applications %>%
  group_by(quarter, examiner_id) %>%
  mutate(PEN_applications = sum(disposal_type == "PEND" & !duplicated(application_number)))

applications <- applications %>%
  group_by(quarter,examiner_art_unit) %>%
  mutate(examiner_art_unit_num =  n_distinct(examiner_id))%>%
  ungroup()

applications <- applications %>%
  group_by(quarter, examiner_art_unit) %>%
  mutate(women_in_art_unit  = sum(gender.y == "female" & !duplicated(examiner_id)))

applications <- applications %>%
  group_by(quarter, examiner_art_unit) %>%
  mutate(Asian_in_art_unit  = sum(race.y == "Asian" & !duplicated(examiner_id)))

applications <- applications %>%
  group_by(quarter, examiner_art_unit) %>%
  mutate(Black_in_art_unit  = sum(race.y == "black" & !duplicated(examiner_id)))


applications <- applications %>%
  group_by(quarter, examiner_art_unit) %>%
  mutate(Hispanic_in_art_unit  = sum(race.y == "Hispanic" & !duplicated(examiner_id)))

applications <- applications %>%
  group_by(quarter, examiner_art_unit) %>%
  mutate(Other_in_art_unit  = sum(race.y == "other" & !duplicated(examiner_id)))

applications <- applications %>%
  group_by(quarter, examiner_art_unit) %>%
  mutate(White_in_art_unit  = sum(race.y == "white" & !duplicated(examiner_id)))

```


### Creating separation and au indicator
```{r}

# sort by examiner_id and quarter
applications <- applications %>%
  arrange(examiner_id, quarter)
```

- Drop duplicated columns after merging
```{r}
applications_selected <- applications %>%
  select(
    application_number,
    examiner_id,
    examiner_name_first,
    examiner_name_middle,
    examiner_name_last,
    tc,
    quarter,
    new_applications,
    ISSUED_applications,
    abn_applications,
    PEN_applications,
    examiner_art_unit,
    women_in_art_unit,
    Asian_in_art_unit,
    Black_in_art_unit,
    Other_in_art_unit,
    White_in_art_unit,
    ends_with(".x")  # Select columns that end with '_x'
  ) %>%
  rename_with(~ str_remove(., ".x"), ends_with(".x"))  # Remove the '_x' suffix

```

**in order to add separation we must know when each of employee's max quarter and compare it to max quarter in the dataset**
```{r}
# find the latest time quarter for each examiner
applications_selected %>%
  group_by(examiner_id) %>%
  mutate(max_quarter = max(quarter))

```

```{r}
# unique quarters values and count  (when is the latest quarter in the dataset?)
applications_selected %>%
  group_by(quarter) %>%
  summarise(n = n_distinct(examiner_id)) %>%
  arrange(desc(quarter)) %>% head(5)

```


```{r}
overall_max_quarter <- "2017/1"

# Create the separation_indicator
applications_selected <- applications_selected %>%
  group_by(examiner_id) %>%
  mutate(max_quarter_examiner = max(quarter)) %>%
  ungroup() %>%
  mutate(separation_indicator = if_else(max_quarter_examiner < overall_max_quarter, 1, 0))

applications_selected


```

- Our separation data shoudl look like 0 0 0 0 0 0 1 -> this one indicates that the employee has left the company
- if 0 0 0 0 0 0 0 -> this one indicates that the employee is still working for the company

**Add AU move Indicator**
```{r}
applications_selected <- applications_selected %>%
  group_by(examiner_id) %>%
  mutate(au_move_indicator = if_else(examiner_art_unit != lag(examiner_art_unit), 1, 0)) %>%
  ungroup()

# Fill NA for the au_move_indicator
applications_selected <- applications_selected %>%
  mutate(au_move_indicator = if_else(is.na(au_move_indicator), 0, au_move_indicator))

applications_selected
```

Not sure what we are expected to create here: some employees change art unit multiple times in one quarter (most likely because they have multiple ongoing projects). However, summing them would make the "indicator" greater than one. Yet, this sum should indicate how many times one moved art unit in one quarter.

### Some other cleaning

```{r}
# drop columns: assumed we don't need them anymore
applications_selected <- applications_selected %>%
  select(-c(max_quarter_examiner, earliest_date, latest_date, tc))

# fill NA for the woman_in_art_unit
applications_selected <- applications_selected %>%
  mutate(women_in_art_unit = if_else(is.na(women_in_art_unit), 0, women_in_art_unit))

# info about the dataset
glimpse(applications_selected)
```

Create a quarterly aggregated panel dataset
- how do we aggregate columns like number of race in art unit? because some examiner changes art unit within each quarter
- again how should we deal with art unit column?
-> next file


```{r}
write_feather(applications_selected, paste0(data_path,"app_applications_starter_coded2.feather"))
```
```

