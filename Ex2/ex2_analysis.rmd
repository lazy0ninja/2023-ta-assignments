---
title: "Exercise 2 regression"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(arrow)


```

```{r}
# Read in the data
data_path <- "/Users/kaz/Desktop/MMA - WINTER Code/"
df <- read_feather(paste0(data_path,"app_applications_starter_coded2.feather"))
```


### Create a quarterly aggregated panel dataset
- how do we aggregate columns like number of race in art unit? because some examiner changes art unit within each quarter
- again how should we deal with art unit columns?


```{r}
# individual level data
indi_attributes <- df %>%
  select(gender, race, examiner_id) %>%
  distinct(examiner_id, .keep_all = TRUE)
```



### Aggreagate the data by quarter
```{r}

df_quarter <- df %>%
        group_by(examiner_id, quarter) %>%
        summarize(
                new_applications = mean(new_applications, na.rm = TRUE),
                ISSUED_applications = mean(ISSUED_applications, na.rm = TRUE),
                total_abn_applications = mean(abn_applications, na.rm = TRUE),
                total_PEN_applications = mean(PEN_applications, na.rm = TRUE),
                tenure_days = mean(tenure_days, na.rm = TRUE),
                women_in_art_unit = mean(women_in_art_unit, na.rm = TRUE),
                Asian_in_art_unit = mean(Asian_in_art_unit, na.rm = TRUE),
                Black_in_art_unit = mean(Black_in_art_unit, na.rm = TRUE),
                Other_in_art_unit = mean(Other_in_art_unit, na.rm = TRUE),
                White_in_art_unit = mean(White_in_art_unit, na.rm = TRUE),
                separation_indicator = mean(separation_indicator, na.rm = TRUE),
                au_move_indicator = sum(au_move_indicator, na.rm = TRUE)
        )

df_quarter


```


### Merge the individual level data with the quarterly aggregated data
```{r}
# merge individual level data with quarterly aggregated data
df_quarter <- df_quarter %>%
        left_join(indi_attributes, by = "examiner_id")
```


### Change the data types
```{r}

df_quarter <- df_quarter %>%
        mutate(
                examiner_id = as.integer(examiner_id),
                quarter = as.character(quarter),  # or you could separate into year and quarter
                tenure_days = as.numeric(tenure_days),  # Assuming you keep the .x column
                separation_indicator = as.factor(separation_indicator),
                au_move_indicator = as.integer(au_move_indicator),
                gender = as.factor(gender),
                race = as.factor(race)
        )

# Now check the structure of the dataframe to confirm changes

```

### Check NA and drop them
```{r}
# colsum na
colSums(is.na(df_quarter))
```


```{r}
# drop na
df_quarter <- df_quarter %>%
        drop_na()
```

```{r}
# colsum na
colSums(is.na(df_quarter))
dim(df_quarter)
```





### to-do
1: single variable analysis
2: correlation
3: some interaction analysis
4: regression

### Explatory Data Analysis

```{r}
df_unique <- df_quarter %>%
        distinct(examiner_id, .keep_all = TRUE)

# Now create the gender and race distribution tables
gender_distribution <- table(df_unique$gender)
race_distribution <- table(df_unique$race)

# Print the distributions
print(gender_distribution)
print(race_distribution)
```

```{r}
# col wise na sum
colSums(is.na(df_quarter))
```

```{r}
# drop if quarter is 2017/2
df_quarter <- df_quarter %>%
        filter(quarter != "2017/2")

# largest quarter
max(df_quarter$quarter)
```

```{r}
# modify separation indicator
# for each examiner, make the last quarter's separation indicator as 1 and the rest as 0
df_quarter %>%
        group_by(examiner_id) %>%
        mutate(
                separation_indicator = ifelse(
                        quarter == max(quarter),
                        1,
                        0
                )
        )
```

### create dataset for each analysis
```{r}
# for turnover analysis
df_turn <- df_quarter
df_mobi <- df_quarter %>% select(-separation_indicator)
```

### Run regression for turnover analysis
- time is a variable we created to represent the time period for each observation. It allows the model to account for the time until separation.
-
```{r}
# regression for turnover analysis
df_turn <- df_turn %>%
  group_by(examiner_id) %>%
  arrange(quarter) %>%
  mutate(time = row_number()) %>%
  ungroup()

```

```{r}
# How many examiners are in the data?
length(unique(df_turn$examiner_id))
# How many quarters are in the data?
length(unique(df_turn$quarter))
```



```{r}
# Model with time fixed effects
separation_model <- glm(separation_indicator ~ time + au_move_indicator + new_applications + ISSUED_applications + total_abn_applications + total_PEN_applications + gender + race + women_in_art_unit + Asian_in_art_unit + Black_in_art_unit + Other_in_art_unit + White_in_art_unit, family = binomial(link = "logit"), data = df_turn)

summary(separation_model)
```


**Adding fixed effects with dummies might be computationally hard**
**I don't know how to do fixed effects for non-linear like logit**


- Control for Time-Specific Effects: By including time dummies (e.g., for each quarter), you control for any unobserved variables that vary over time but are constant across entities (examiners). This might include factors like policy changes, economic trends, seasonal effects, or other time-related influences.
```{r}
# Assuming df_turn already has 'quarter' as a factor
df_turn$quarter <- factor(df_turn$quarter)

# Model with time fixed effects
separation_model <- glm(separation_indicator ~ time + au_move_indicator + new_applications + ISSUED_applications + total_abn_applications + total_PEN_applications + gender + race + women_in_art_unit + Asian_in_art_unit + Black_in_art_unit + Other_in_art_unit + White_in_art_unit + model.matrix(~ quarter - 1, data = df_turn), family = binomial(link = "logit"), data = df_turn)

summary(separation_model)
```


### Without Time Dummies
| Variable               | Coefficient | Significance |
|------------------------|-------------|--------------|
| Intercept              | -1.0953294  | ***          |
| time                   | 0.0240507   | ***          |
| au_move_indicator      | -0.0012826  |              |
| new_applications       | 0.0317154   | ***          |
| ISSUED_applications    | -0.0033750  | .            |
| total_abn_applications | 0.0267939   | ***          |
| total_PEN_applications | NA          | NA           |
| genderfemale           | 0.0677485   | ***          |
| raceAsian              | -0.0047479  |              |
| raceblack              | 0.0764690   | **           |
| raceHispanic           | -0.2409096  | ***          |
| raceother              | -0.4673176  | *            |
| women_in_art_unit      | 0.0434395   | ***          |
| Asian_in_art_unit      | -0.0212711  | ***          |
| Black_in_art_unit      | 0.1326289   | ***          |
| Other_in_art_unit      | 0.2296540   | ***          |
| White_in_art_unit      | 0.0049194   | ***          |


### With Time Dummies
| Variable            | Coefficient | Significance |
|---------------------|-------------|--------------|
| Intercept           | 2.842e+11   |              |
| time                | 0.02405     | ***          |
| au_move_indicator   | -0.0012826  |              |
| new_applications    | 0.0317154   | ***          |
| ISSUED_applications | -0.0033750  |              |
| total_abn_applications | 0.0267939 | ***          |
| total_PEN_applications | NA        | NA           |
| genderfemale        | 0.0677485   | ***          |
| raceAsian           | -0.009352   |              |
| raceblack           | 0.0764690   | **           |
| raceHispanic        | -0.2490906  | ***          |
| raceother           | -0.4673176  | *            |
| women_in_art_unit   | 0.0434395   | ***          |
| Asian_in_art_unit   | -0.0212711  | ***          |
| Black_in_art_unit   | 0.1326289   | ***          |
| Other_in_art_unit   | 0.2296540   | ***          |
| White_in_art_unit   | 0.0049194   | ***          |






### Run regression for mobility analysis

The Poisson model is appropriate when your response variable represents count data and you expect the variance to be equal to the mean (a key assumption of the Poisson distribution). If the variance significantly exceeds the mean, a negative binomial model might be more appropriate.

```{r}
# check the assumption
mean(df_mobi$au_move_indicator)
var(df_mobi$au_move_indicator)
```


```{r}
# au_move_indicator hist
hist(df_mobi$au_move_indicator, breaks = 50)
```


```{r}
library(plm)
# Convert the data frame to a pdata.frame, specifying the index for entity and time
pdata <- pdata.frame(df_mobi, index = c("examiner_id", "quarter"))

# Fit the fixed effects model
fe_model <- plm(au_move_indicator ~ new_applications + ISSUED_applications +
  total_abn_applications + tenure_days + gender + race +
  women_in_art_unit + Asian_in_art_unit + Black_in_art_unit +
  Other_in_art_unit + White_in_art_unit,
                data = pdata, model = "within")

summary(fe_model)
```


- you can see that time-invarient variables are dropped because they are not informative in the fixed effects model (gneder, race, tenure days...)

| Variable             | Coefficient | Significance |
|----------------------|-------------|--------------|
| new_applications     | -0.00030712 |              |
| ISSUED_applications  | 0.08934460  | ***          |
| total_abn_applications | 0.24136075 | ***          |
| women_in_art_unit    | -0.00051123 |              |
| Asian_in_art_unit    | 0.01950606  | ***          |
| Black_in_art_unit    | 0.07589236  | ***          |
| Other_in_art_unit    | 0.20590610  | **           |
| White_in_art_unit    | 0.07331964  | ***          |
